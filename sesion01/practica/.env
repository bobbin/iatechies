# URL del servidor de Ollama (local por defecto)
OLLAMA_URL=http://localhost:11434

# Modelos por defecto (ajusta según tu máquina)
OLLAMA_MODEL_TEXT=gemma:2b
OLLAMA_MODEL_VISION=llava

# Archivo de métricas (CSV)
METRICS_FILE=metrics.csv

# Segundos para mantener el modelo caliente (keep_alive)
KEEP_ALIVE_SECS=300

# --- CLOUD (opcional) ---
# Cambia a 'cloud' para usar Ollama Cloud en lugar de local
# OLLAMA_MODE=cloud

# Endpoint Cloud (suele ser este; ajusta si cambia)
# OLLAMA_CLOUD_URL=https://api.ollama.ai

# API Key de Ollama Cloud
# OLLAMA_CLOUD_API_KEY=ollama-xxxxxxxxxxxxxxxxxxxxxxxx
